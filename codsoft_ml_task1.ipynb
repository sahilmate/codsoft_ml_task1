{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\sahil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.9.1)\n",
      "Requirement already satisfied: click in c:\\users\\sahil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sahil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from nltk) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahil\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from click->nltk) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: C:\\Users\\sahil\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sahil\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "# Load train and test data\n",
    "train_df = pd.read_csv(r'archive/Genre Classification Dataset/train_data.txt', sep=':::', header=None, names=['ID', 'Title', 'Genre', 'Description'], engine='python')\n",
    "test_df = pd.read_csv(r'archive/Genre Classification Dataset/test_data.txt', sep=':::', header=None, names=['ID', 'Title', 'Description'], engine='python')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text function\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape After Cleaning: (54214, 4)\n",
      "Test Data Shape After Cleaning: (54200, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sahil\\AppData\\Local\\Temp\\ipykernel_20516\\2567317817.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Genre'].fillna('unknown', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Apply cleaning to the data\n",
    "train_df['Description'] = train_df['Description'].apply(clean_text)\n",
    "test_df['Description'] = test_df['Description'].apply(clean_text)\n",
    "\n",
    "# Handle missing values\n",
    "train_df['Genre'].fillna('unknown', inplace=True)\n",
    "train_df = train_df[train_df['Description'].str.strip().notna()]\n",
    "test_df = test_df[test_df['Description'].str.strip().notna()]\n",
    "\n",
    "# Print shapes of the cleaned data\n",
    "print(\"Train Data Shape After Cleaning:\", train_df.shape)\n",
    "print(\"Test Data Shape After Cleaning:\", test_df.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for training\n",
    "X_train = train_df['Description']\n",
    "y_train = train_df['Genre'].str.strip()\n",
    "\n",
    "# Transform text using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                          Title Predicted Genre\n",
      "0   1          Edgar's Lunch (1998)            drama\n",
      "1   2      La guerra de pap√° (1977)            drama\n",
      "2   3   Off the Beaten Track (2010)      documentary\n",
      "3   4        Meu Amigo Hindu (2015)            drama\n",
      "4   5             Er nu zhai (1955)            drama\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prepare and predict on the test data\n",
    "X_test = test_df['Description'].tolist()\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "\n",
    "# Add predictions to the test DataFrame\n",
    "test_df['Predicted Genre'] = predictions\n",
    "\n",
    "# Display results\n",
    "print(test_df[['ID', 'Title', 'Predicted Genre']].head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
